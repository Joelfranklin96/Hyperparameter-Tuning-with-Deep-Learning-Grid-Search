{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%env KERAS_BACKEND=theano","execution_count":2,"outputs":[{"output_type":"stream","text":"env: KERAS_BACKEND=theano\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the necessary packages\n\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom sklearn.preprocessing import StandardScaler","execution_count":3,"outputs":[{"output_type":"stream","text":"Using Theano backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading the file\n\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # Shape of 'df'","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(768, 9)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns # Prints columns of 'df'","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe() # Displays properties of each column","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>120.894531</td>\n      <td>69.105469</td>\n      <td>20.536458</td>\n      <td>79.799479</td>\n      <td>31.992578</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>31.972618</td>\n      <td>19.355807</td>\n      <td>15.952218</td>\n      <td>115.244002</td>\n      <td>7.884160</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>62.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>27.300000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>23.000000</td>\n      <td>30.500000</td>\n      <td>32.000000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>127.250000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prints count of rows where respective column value = 0\n\nprint(df[df['Glucose'] == 0]['Glucose'].count())\nprint(df[df['BloodPressure'] == 0]['BloodPressure'].count())\nprint(df[df['SkinThickness'] == 0]['SkinThickness'].count())\nprint(df[df['Insulin'] == 0]['Insulin'].count())\nprint(df[df['BMI'] == 0]['BMI'].count())","execution_count":8,"outputs":[{"output_type":"stream","text":"5\n35\n227\n374\n11\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rows with missing values are dropped\n\ndf.dropna(inplace = True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = df.values","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset[:,0:8]\ny = dataset[:,8].astype('int')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardization\n\na = StandardScaler()\na.fit(X)\nX_standardized = a.transform(X)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_standardized).describe()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                  0             1             2             3             4  \\\ncount  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02   \nmean   2.544261e-17  3.614007e-18 -1.327244e-17  7.994184e-17 -3.556183e-17   \nstd    1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00   \nmin   -1.141852e+00 -3.783654e+00 -3.572597e+00 -1.288212e+00 -6.928906e-01   \n25%   -8.448851e-01 -6.852363e-01 -3.673367e-01 -1.288212e+00 -6.928906e-01   \n50%   -2.509521e-01 -1.218877e-01  1.496408e-01  1.545332e-01 -4.280622e-01   \n75%    6.399473e-01  6.057709e-01  5.632228e-01  7.190857e-01  4.120079e-01   \nmax    3.906578e+00  2.444478e+00  2.734528e+00  4.921866e+00  6.652839e+00   \n\n                  5             6             7  \ncount  7.680000e+02  7.680000e+02  7.680000e+02  \nmean   2.295979e-16  2.398978e-16  1.857600e-16  \nstd    1.000652e+00  1.000652e+00  1.000652e+00  \nmin   -4.060474e+00 -1.189553e+00 -1.041549e+00  \n25%   -5.955785e-01 -6.889685e-01 -7.862862e-01  \n50%    9.419788e-04 -3.001282e-01 -3.608474e-01  \n75%    5.847705e-01  4.662269e-01  6.602056e-01  \nmax    4.455807e+00  5.883565e+00  4.063716e+00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.544261e-17</td>\n      <td>3.614007e-18</td>\n      <td>-1.327244e-17</td>\n      <td>7.994184e-17</td>\n      <td>-3.556183e-17</td>\n      <td>2.295979e-16</td>\n      <td>2.398978e-16</td>\n      <td>1.857600e-16</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.141852e+00</td>\n      <td>-3.783654e+00</td>\n      <td>-3.572597e+00</td>\n      <td>-1.288212e+00</td>\n      <td>-6.928906e-01</td>\n      <td>-4.060474e+00</td>\n      <td>-1.189553e+00</td>\n      <td>-1.041549e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-8.448851e-01</td>\n      <td>-6.852363e-01</td>\n      <td>-3.673367e-01</td>\n      <td>-1.288212e+00</td>\n      <td>-6.928906e-01</td>\n      <td>-5.955785e-01</td>\n      <td>-6.889685e-01</td>\n      <td>-7.862862e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-2.509521e-01</td>\n      <td>-1.218877e-01</td>\n      <td>1.496408e-01</td>\n      <td>1.545332e-01</td>\n      <td>-4.280622e-01</td>\n      <td>9.419788e-04</td>\n      <td>-3.001282e-01</td>\n      <td>-3.608474e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.399473e-01</td>\n      <td>6.057709e-01</td>\n      <td>5.632228e-01</td>\n      <td>7.190857e-01</td>\n      <td>4.120079e-01</td>\n      <td>5.847705e-01</td>\n      <td>4.662269e-01</td>\n      <td>6.602056e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.906578e+00</td>\n      <td>2.444478e+00</td>\n      <td>2.734528e+00</td>\n      <td>4.921866e+00</td>\n      <td>6.652839e+00</td>\n      <td>4.455807e+00</td>\n      <td>5.883565e+00</td>\n      <td>4.063716e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a Neural Network ","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the necessary packages\n\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter tuning of Batch size and Epochs","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the model\n\ndef create_model():\n    model = Sequential()\n    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0)\n\n# Define the grid search parameters\n\nbatch_size = [10,20,40]\nepochs = [10,50,100]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(batch_size = batch_size,epochs = epochs)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n# Summarize the results\n\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{},{} with: {}'.format(mean, stdev, param))\n    ","execution_count":17,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(NSPLIT_WARNING, FutureWarning)\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting 3 folds for each of 9 candidates, totalling 27 fits\n[CV] batch_size=10, epochs=10 ........................................\n[CV] ............ batch_size=10, epochs=10, score=0.617, total=  47.8s\n[CV] batch_size=10, epochs=10 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   47.8s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=10, epochs=10, score=0.758, total=   2.0s\n[CV] batch_size=10, epochs=10 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   49.8s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=10, epochs=10, score=0.812, total=   2.2s\n[CV] batch_size=10, epochs=50 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   52.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=10, epochs=50, score=0.734, total=   3.5s\n[CV] batch_size=10, epochs=50 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   55.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=10, epochs=50, score=0.734, total=   3.2s\n[CV] batch_size=10, epochs=50 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   58.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=10, epochs=50, score=0.801, total=   3.5s\n[CV] batch_size=10, epochs=100 .......................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.0min remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ........... batch_size=10, epochs=100, score=0.723, total=   5.7s\n[CV] batch_size=10, epochs=100 .......................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ........... batch_size=10, epochs=100, score=0.660, total=   8.0s\n[CV] batch_size=10, epochs=100 .......................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.3min remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ........... batch_size=10, epochs=100, score=0.805, total=   5.1s\n[CV] batch_size=20, epochs=10 ........................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ............ batch_size=20, epochs=10, score=0.754, total=   2.1s\n[CV] batch_size=20, epochs=10 ........................................\n[CV] ............ batch_size=20, epochs=10, score=0.723, total=   1.8s\n[CV] batch_size=20, epochs=10 ........................................\n[CV] ............ batch_size=20, epochs=10, score=0.801, total=   2.1s\n[CV] batch_size=20, epochs=50 ........................................\n[CV] ............ batch_size=20, epochs=50, score=0.734, total=   2.7s\n[CV] batch_size=20, epochs=50 ........................................\n[CV] ............ batch_size=20, epochs=50, score=0.746, total=   2.5s\n[CV] batch_size=20, epochs=50 ........................................\n[CV] ............ batch_size=20, epochs=50, score=0.793, total=   2.7s\n[CV] batch_size=20, epochs=100 .......................................\n[CV] ........... batch_size=20, epochs=100, score=0.746, total=   3.5s\n[CV] batch_size=20, epochs=100 .......................................\n[CV] ........... batch_size=20, epochs=100, score=0.738, total=   3.5s\n[CV] batch_size=20, epochs=100 .......................................\n[CV] ........... batch_size=20, epochs=100, score=0.766, total=   3.6s\n[CV] batch_size=40, epochs=10 ........................................\n[CV] ............ batch_size=40, epochs=10, score=0.754, total=   1.7s\n[CV] batch_size=40, epochs=10 ........................................\n[CV] ............ batch_size=40, epochs=10, score=0.723, total=   2.0s\n[CV] batch_size=40, epochs=10 ........................................\n[CV] ............ batch_size=40, epochs=10, score=0.805, total=   2.0s\n[CV] batch_size=40, epochs=50 ........................................\n[CV] ............ batch_size=40, epochs=50, score=0.742, total=   2.1s\n[CV] batch_size=40, epochs=50 ........................................\n[CV] ............ batch_size=40, epochs=50, score=0.727, total=   2.3s\n[CV] batch_size=40, epochs=50 ........................................\n[CV] ............ batch_size=40, epochs=50, score=0.770, total=   2.4s\n[CV] batch_size=40, epochs=100 .......................................\n[CV] ........... batch_size=40, epochs=100, score=0.727, total=   2.5s\n[CV] batch_size=40, epochs=100 .......................................\n[CV] ........... batch_size=40, epochs=100, score=0.742, total=   2.8s\n[CV] batch_size=40, epochs=100 .......................................\n[CV] ........... batch_size=40, epochs=100, score=0.777, total=   2.8s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.1min finished\n","name":"stderr"},{"output_type":"stream","text":"Best : 0.7604166666666666, using {'batch_size': 40, 'epochs': 10}\n0.7291666666666666,0.0822685885361006 with: {'batch_size': 10, 'epochs': 10}\n0.7565104166666666,0.031304206458779446 with: {'batch_size': 10, 'epochs': 50}\n0.7291666666666666,0.05918394884043496 with: {'batch_size': 10, 'epochs': 100}\n0.7591145833333334,0.03210632293213009 with: {'batch_size': 20, 'epochs': 10}\n0.7578125,0.025315393353155705 with: {'batch_size': 20, 'epochs': 50}\n0.75,0.01149968862803105 with: {'batch_size': 20, 'epochs': 100}\n0.7604166666666666,0.03380404944204992 with: {'batch_size': 40, 'epochs': 10}\n0.74609375,0.017758049084617 with: {'batch_size': 40, 'epochs': 50}\n0.7486979166666666,0.021236336497786574 with: {'batch_size': 40, 'epochs': 100}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter tuning of Learning rate and Drop out rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dropout\n\n# Defining the model\n\ndef create_model(learning_rate,dropout_rate):\n    model = Sequential()\n    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = learning_rate)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\n\nlearning_rate = [0.001,0.01,0.1]\ndropout_rate = [0.0,0.1,0.2]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n# Summarize the results\n\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{},{} with: {}'.format(mean, stdev, param))","execution_count":18,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(NSPLIT_WARNING, FutureWarning)\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting 3 folds for each of 9 candidates, totalling 27 fits\n[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.770, total=   2.8s\n[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.660, total=   2.3s\n[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.777, total=   2.8s\n[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.8s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.754, total=   2.6s\n[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.746, total=   2.0s\n[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.3s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.801, total=   2.4s\n[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   14.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.766, total=   2.2s\n[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   16.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.746, total=   2.7s\n[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   19.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.793, total=   2.7s\n[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.3s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.773, total=  12.6s\n[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.730, total=   3.0s\n[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.805, total=   3.2s\n[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.742, total=   2.7s\n[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.742, total=   3.2s\n[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.801, total=   2.7s\n[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.723, total=   3.3s\n[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.738, total=   3.1s\n[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.730, total=   2.4s\n[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.617, total=   3.0s\n[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.660, total=   2.7s\n[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.676, total=   2.3s\n[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.617, total=   2.7s\n[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.730, total=   2.8s\n[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.805, total=   2.4s\n[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.730, total=   2.8s\n[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.734, total=   2.8s\n[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.805, total=   2.5s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.4min finished\n","name":"stderr"},{"output_type":"stream","text":"Best : 0.76953125, using {'dropout_rate': 0.1, 'learning_rate': 0.001}\n0.7356770833333334,0.053496454646286815 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n0.7669270833333334,0.024150048165353395 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n0.7682291666666666,0.019225030026345572 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n0.76953125,0.030425316264447715 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n0.76171875,0.027621358640099514 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n0.73046875,0.00637887953849786 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n0.6510416666666666,0.024773824987552668 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n0.7174479166666666,0.0770982882452472 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n0.7565104166666666,0.03410364805653332 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter tuning of Activation Function and Kernel Initializer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the model\n\ndef create_model(activation_function,init):\n    model = Sequential()\n    model.add(Dense(8,input_dim = 8,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(0.1))\n    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\n\nactivation_function = ['softmax','relu','tanh','linear']\ninit = ['uniform','normal','zero']\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(activation_function = activation_function,init = init)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n# Summarize the results\n\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{},{} with: {}'.format(mean, stdev, param))","execution_count":19,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(NSPLIT_WARNING, FutureWarning)\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting 3 folds for each of 12 candidates, totalling 36 fits\n[CV] activation_function=softmax, init=uniform .......................\n[CV]  activation_function=softmax, init=uniform, score=0.617, total=   5.6s\n[CV] activation_function=softmax, init=uniform .......................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=uniform, score=0.340, total=   2.2s\n[CV] activation_function=softmax, init=uniform .......................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=uniform, score=0.676, total=   2.2s\n[CV] activation_function=softmax, init=normal ........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=normal, score=0.617, total=   2.1s\n[CV] activation_function=softmax, init=normal ........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.1s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=normal, score=0.660, total=   2.4s\n[CV] activation_function=softmax, init=normal ........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=normal, score=0.676, total=   2.0s\n[CV] activation_function=softmax, init=zero ..........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=zero, score=0.383, total=   2.1s\n[CV] activation_function=softmax, init=zero ..........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   18.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=zero, score=0.660, total=   1.7s\n[CV] activation_function=softmax, init=zero ..........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   20.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=softmax, init=zero, score=0.676, total=   2.1s\n[CV] activation_function=relu, init=uniform ..........................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  activation_function=relu, init=uniform, score=0.762, total=   2.3s\n[CV] activation_function=relu, init=uniform ..........................\n[CV]  activation_function=relu, init=uniform, score=0.703, total=   1.9s\n[CV] activation_function=relu, init=uniform ..........................\n[CV]  activation_function=relu, init=uniform, score=0.676, total=   2.3s\n[CV] activation_function=relu, init=normal ...........................\n[CV]  activation_function=relu, init=normal, score=0.617, total=   2.2s\n[CV] activation_function=relu, init=normal ...........................\n[CV]  activation_function=relu, init=normal, score=0.660, total=   2.6s\n[CV] activation_function=relu, init=normal ...........................\n[CV]  activation_function=relu, init=normal, score=0.738, total=   2.6s\n[CV] activation_function=relu, init=zero .............................\n[CV] . activation_function=relu, init=zero, score=0.617, total=   1.8s\n[CV] activation_function=relu, init=zero .............................\n[CV] . activation_function=relu, init=zero, score=0.660, total=   2.2s\n[CV] activation_function=relu, init=zero .............................\n[CV] . activation_function=relu, init=zero, score=0.676, total=   2.2s\n[CV] activation_function=tanh, init=uniform ..........................\n[CV]  activation_function=tanh, init=uniform, score=0.754, total=   4.1s\n[CV] activation_function=tanh, init=uniform ..........................\n[CV]  activation_function=tanh, init=uniform, score=0.715, total=   2.3s\n[CV] activation_function=tanh, init=uniform ..........................\n[CV]  activation_function=tanh, init=uniform, score=0.809, total=   1.9s\n[CV] activation_function=tanh, init=normal ...........................\n[CV]  activation_function=tanh, init=normal, score=0.750, total=   2.5s\n[CV] activation_function=tanh, init=normal ...........................\n[CV]  activation_function=tanh, init=normal, score=0.695, total=   2.1s\n[CV] activation_function=tanh, init=normal ...........................\n[CV]  activation_function=tanh, init=normal, score=0.789, total=   2.5s\n[CV] activation_function=tanh, init=zero .............................\n[CV] . activation_function=tanh, init=zero, score=0.617, total=   1.8s\n[CV] activation_function=tanh, init=zero .............................\n[CV] . activation_function=tanh, init=zero, score=0.660, total=   2.2s\n[CV] activation_function=tanh, init=zero .............................\n[CV] . activation_function=tanh, init=zero, score=0.676, total=   1.8s\n[CV] activation_function=linear, init=uniform ........................\n[CV]  activation_function=linear, init=uniform, score=0.738, total=   2.2s\n[CV] activation_function=linear, init=uniform ........................\n[CV]  activation_function=linear, init=uniform, score=0.688, total=   2.2s\n[CV] activation_function=linear, init=uniform ........................\n[CV]  activation_function=linear, init=uniform, score=0.793, total=   1.8s\n[CV] activation_function=linear, init=normal .........................\n[CV]  activation_function=linear, init=normal, score=0.758, total=   2.4s\n[CV] activation_function=linear, init=normal .........................\n[CV]  activation_function=linear, init=normal, score=0.711, total=   2.1s\n[CV] activation_function=linear, init=normal .........................\n[CV]  activation_function=linear, init=normal, score=0.797, total=   2.4s\n[CV] activation_function=linear, init=zero ...........................\n[CV]  activation_function=linear, init=zero, score=0.617, total=   1.7s\n[CV] activation_function=linear, init=zero ...........................\n[CV]  activation_function=linear, init=zero, score=0.660, total=   2.1s\n[CV] activation_function=linear, init=zero ...........................\n[CV]  activation_function=linear, init=zero, score=0.676, total=   1.7s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.4min finished\n","name":"stderr"},{"output_type":"stream","text":"Best : 0.7591145833333334, using {'activation_function': 'tanh', 'init': 'uniform'}\n0.5442708333333334,0.14651764668438594 with: {'activation_function': 'softmax', 'init': 'uniform'}\n0.6510416666666666,0.024773824987552668 with: {'activation_function': 'softmax', 'init': 'normal'}\n0.5729166666666666,0.134575210184419 with: {'activation_function': 'softmax', 'init': 'zero'}\n0.7135416666666666,0.03584869765087553 with: {'activation_function': 'relu', 'init': 'uniform'}\n0.671875,0.050125980611771245 with: {'activation_function': 'relu', 'init': 'normal'}\n0.6510416666666666,0.024773824987552668 with: {'activation_function': 'relu', 'init': 'zero'}\n0.7591145833333334,0.038450060052691144 with: {'activation_function': 'tanh', 'init': 'uniform'}\n0.7447916666666666,0.038450060052691144 with: {'activation_function': 'tanh', 'init': 'normal'}\n0.6510416666666666,0.024773824987552668 with: {'activation_function': 'tanh', 'init': 'zero'}\n0.7395833333333334,0.04306727970974278 with: {'activation_function': 'linear', 'init': 'uniform'}\n0.7552083333333334,0.03513212907091677 with: {'activation_function': 'linear', 'init': 'normal'}\n0.6510416666666666,0.024773824987552668 with: {'activation_function': 'linear', 'init': 'zero'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter tuning of number of Neurons in activation layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the model\n\ndef create_model(neuron1,neuron2):\n    model = Sequential()\n    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n\n# Define the grid search parameters\n\nneuron1 = [4,8,16]\nneuron2 = [2,4,8]\n\n# Make a dictionary of the grid search parameters\n\nparam_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n\n# Build and fit the GridSearchCV\n\ngrid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\ngrid_result = grid.fit(X_standardized,y)\n\n# Summarize the results\n\nprint('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{},{} with: {}'.format(mean, stdev, param))","execution_count":20,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(NSPLIT_WARNING, FutureWarning)\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Fitting 3 folds for each of 9 candidates, totalling 27 fits\n[CV] neuron1=4, neuron2=2 ............................................\n[CV] ................ neuron1=4, neuron2=2, score=0.715, total=   2.4s\n[CV] neuron1=4, neuron2=2 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=2, score=0.711, total=   1.9s\n[CV] neuron1=4, neuron2=2 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=2, score=0.781, total=   2.3s\n[CV] neuron1=4, neuron2=4 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=4, score=0.746, total=   2.0s\n[CV] neuron1=4, neuron2=4 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=4, score=0.703, total=   2.4s\n[CV] neuron1=4, neuron2=4 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=4, score=0.770, total=   1.9s\n[CV] neuron1=4, neuron2=8 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   12.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=8, score=0.719, total=   2.4s\n[CV] neuron1=4, neuron2=8 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   15.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=8, score=0.707, total=   1.9s\n[CV] neuron1=4, neuron2=8 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   17.3s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=4, neuron2=8, score=0.781, total=   2.4s\n[CV] neuron1=8, neuron2=2 ............................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   19.6s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ................ neuron1=8, neuron2=2, score=0.734, total=   2.3s\n[CV] neuron1=8, neuron2=2 ............................................\n[CV] ................ neuron1=8, neuron2=2, score=0.688, total=   1.9s\n[CV] neuron1=8, neuron2=2 ............................................\n[CV] ................ neuron1=8, neuron2=2, score=0.785, total=   2.4s\n[CV] neuron1=8, neuron2=4 ............................................\n[CV] ................ neuron1=8, neuron2=4, score=0.746, total=   1.9s\n[CV] neuron1=8, neuron2=4 ............................................\n[CV] ................ neuron1=8, neuron2=4, score=0.684, total=   2.4s\n[CV] neuron1=8, neuron2=4 ............................................\n[CV] ................ neuron1=8, neuron2=4, score=0.801, total=   1.9s\n[CV] neuron1=8, neuron2=8 ............................................\n[CV] ................ neuron1=8, neuron2=8, score=0.758, total=   2.4s\n[CV] neuron1=8, neuron2=8 ............................................\n[CV] ................ neuron1=8, neuron2=8, score=0.703, total=   1.9s\n[CV] neuron1=8, neuron2=8 ............................................\n[CV] ................ neuron1=8, neuron2=8, score=0.801, total=   2.4s\n[CV] neuron1=16, neuron2=2 ...........................................\n[CV] ............... neuron1=16, neuron2=2, score=0.762, total=   2.4s\n[CV] neuron1=16, neuron2=2 ...........................................\n[CV] ............... neuron1=16, neuron2=2, score=0.684, total=   1.9s\n[CV] neuron1=16, neuron2=2 ...........................................\n[CV] ............... neuron1=16, neuron2=2, score=0.797, total=   2.3s\n[CV] neuron1=16, neuron2=4 ...........................................\n[CV] ............... neuron1=16, neuron2=4, score=0.758, total=   1.9s\n[CV] neuron1=16, neuron2=4 ...........................................\n[CV] ............... neuron1=16, neuron2=4, score=0.711, total=   2.3s\n[CV] neuron1=16, neuron2=4 ...........................................\n[CV] ............... neuron1=16, neuron2=4, score=0.809, total=   1.9s\n[CV] neuron1=16, neuron2=8 ...........................................\n[CV] ............... neuron1=16, neuron2=8, score=0.762, total=   2.3s\n[CV] neuron1=16, neuron2=8 ...........................................\n[CV] ............... neuron1=16, neuron2=8, score=0.715, total=   2.0s\n[CV] neuron1=16, neuron2=8 ...........................................\n[CV] ............... neuron1=16, neuron2=8, score=0.801, total=   2.4s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   58.7s finished\n","name":"stderr"},{"output_type":"stream","text":"Best : 0.7591145833333334, using {'neuron1': 16, 'neuron2': 4}\n0.7356770833333334,0.03226435336813507 with: {'neuron1': 4, 'neuron2': 2}\n0.7395833333333334,0.02749832302336312 with: {'neuron1': 4, 'neuron2': 4}\n0.7356770833333334,0.032578114591658346 with: {'neuron1': 4, 'neuron2': 8}\n0.7356770833333334,0.039878627164358214 with: {'neuron1': 8, 'neuron2': 2}\n0.7434895833333334,0.04787702164283915 with: {'neuron1': 8, 'neuron2': 4}\n0.75390625,0.03996356576360106 with: {'neuron1': 8, 'neuron2': 8}\n0.7473958333333334,0.04734286188202563 with: {'neuron1': 16, 'neuron2': 2}\n0.7591145833333334,0.039878627164358214 with: {'neuron1': 16, 'neuron2': 4}\n0.7591145833333334,0.03513212907091677 with: {'neuron1': 16, 'neuron2': 8}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model using optimized values of Hyperparameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Dense(16,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(4,input_dim = 16,kernel_initializer = 'uniform',activation = 'tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1,activation = 'sigmoid'))\n    \n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n    return model\n\n# Create the model\n\nmodel = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_standardized,y)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fbd08ee23c8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = model.predict(X_standardized)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\nprint(accuracy_score(y,y_predict))\nprint(classification_report(y,y_predict))\n","execution_count":26,"outputs":[{"output_type":"stream","text":"0.7760416666666666\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84       500\n           1       0.72      0.59      0.65       268\n\n    accuracy                           0.78       768\n   macro avg       0.76      0.73      0.74       768\nweighted avg       0.77      0.78      0.77       768\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}